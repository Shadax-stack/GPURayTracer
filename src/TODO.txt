Revised TODO:
- CLEAN UP CODE, AND OPTIMIZE STUFF
- Add support for metallic textures. I need to deciede on a file format to keep things tidy in one place (suggeseted by the kind folks on the gp server: gltf)
- Implement GPU reference renderer
- LD sampling
- Faster BVH so I can start tracing more complex scenes

TODO:
1. Verify rendering with CPU renderer, finally ditch it for a GPU renderer- 50% done
2. Add diffuse sampling (layered BRDF?) and then add better texture support
3. LD sampling
4. OBB sampling for lights


Idea: balance between cosine and ggx sampling based on metallic
Actually that means zero specular for diffuse
I will start off with a simple 0.5 probability for now


T

he next goal is to properly finish PBR and do bug testing with it
Then move on to proper NEE

My next focus should be coroutine RT, but that is too complex. Over time once I understand things I will attempt it
My next goal right now is OBB rejection sampling and overall cleaning up the NEE code
Then I will proceed to better BRDFs and materials and what not
Then I will implement cool ideas for NEE I have had
Finally, coroutine RT
Remember the completion deadlien is august 31st so I have a lot time
If I finish ahead of time I can try BDPT

NEE algorithm idea: "Intelligent Next Event Estimation":
1. Split the scene into n voxels (or some other spatial data structure, but voxels seem simplest to me)
2. For each of the voxels, for each light, initialize an array with each value set to 1
3. During rendering, we choose a light according to the PMF of this array (ie, if you have two lights, with their values set 35 and 1 respectively, the first light has a 35/36 chance of being chosen)
4. If we hit the light we picked, increment its value in the array by 1
What we do here is that we keep a record of "most hit lights" for a certain area of our scene and then sample from the record
The only issue I really see here is memory access, since you would need to find a smart way to do the PMF while other threads are reading from it
You could implement a while(true) mutex, but this is a GPU, you are wasting a lot of energy and processing power and there is a chance a thread might just get past right before the mutex locks just in the nick of time
To fix this issue, we suggest that you write to a seperate buffer, so there is ensurity that the PMF will not be updated within a frame
After each frame, each PMF is updated, and samples are drawn from it instead
One possible bug is that, in the case of multiple lights nearby, the PMF might get too biased over time towards a single light (after all, lights that are hit are more frequently sampled from causing them to be hit more often)
Buffer swapping does alievte this issue but not competely
We therefore suggest combining the PMF with an equal-chance PMF for each light, so that the distribution is attempted to be balanced over time
Another possible idea is that "if light x has so many samples, we probably have already reached a good estimation for it, so we should sample other lights instead"
That idea could be used to choose between the "successful-hit PMF" and the "equal-oppurtunity PMF"
Nonetheless, this brings back the issue of sampling tiny lights that have zero contribution 
So instead of an equal opputunity PMF, we should use a normal PMF that most normal people use for NEE

Splitting scene into voxels:
1. Deciede on "voxel side length"
2. Compute AABB of scene
3. Divide into voxels
Access the voxel in the shader is easy as centering the corner voxel's corner on (0,0,0,), and then dividing by voxel side length and casting to integer
This can then be transformed into an index in a SSBO
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

I need new direction. I cannot work on this project 24/7.
First order of business is to rewrite stuff to follow coroutine based RT
To that I will first undo NEE and return to a basic naive unidir path tracer
Then I will rewrite everything to follow courutines
I will implement NEE with MIS afterwards
Then I will add cool BRDFs and whatnot
Then I will ask, "what next"?

Goal to finish all of these: August 31st
Also I think I should delete my CPU renderer because it is slow AF and I could just do unidir PT on my GPU
In fact the first thing I will write is my unidir reference PT with the GPU corountine system

==============================================================
Updated TODO list, 6/15/22, everything below the line is useless

Now that I have a working ray pooling system, I want to take a crack at wavefront path tracing, but path tracing itself is an algorithm that is easy to make mistakes and have hidden bugs. For that reason, I will start off with ray tracing shadows, and then I will eventually modify my algorithm into a path tracer
But even then, path tacer and even just shadows are a ways off. IF anything, I need to optimize before moving on (that's excluding the massive refactoring of variable names and cleaning up code that I still need to do)
But as I type, I wonder if optimizations are really that important. I don't want to spend all summer sitting on this project at the basic stuff, nor do I want impatience to blind me

By the way, code rewrites can always be postponed, it is given that I will eventually rewrite the portions that I am working on (which actually matter) so as I code I can also refactor

Here's what I will do: 
- Thursday and Friday are reading days for efficent BVH traversal
- Saturday and Sunday are implementing them

On Monday I will move on to shadow ray tracing and may go for whitted style ray tacing via path tracing

goals:
- Reorganize shader code
- Properly seperate kernels
- Fix the bug when you look at rays that don't exist (becuase they were removed from the ray pool) it starts drowning your screen in undefined from the top. This probably requires indirect compute now
- Need to have different traversal logic for shadow (we only need an obstruction on the shadow segment, not the closest one on it), so we can have better performance

Path trace algorithm:
- Gen rays and get closest primary vertex as usual (refactor this later)
- Shade kernel generates a new ray and its associated BRDF, mults with throughput
- Extend the ray into the path
- Go back to shade kernel unless we have emissive object

Better rewrite:
- Generate kernel runs and outputs rays according to the camera
- Extend kernel traces these rays and finds the closest intersection. If the closest intersection happens to be an emissive light, we output that times the throughput into our color buffer, otherwise we output hte vertex into the ray buffer
- Shade kernel uses the previously found vertex and generates a new ray to for the extend kernel to extend the path by. It also multiplies the throughput by the BRDF for that ray

Accumulation is trivial. We read from the color buffer in the extend kernel, multiply it by currNumSamples-1, add our new sample, and divide by currNumSamples, and write back to the buffer

NEW TODO 6/19:
- Add NEE support (and maybe shader preprocessing args to turn on/off direction lights)
- Add support for a wider variety of materials (reflection, refraction, PBR, etc)

NEE implmentation
First of all, I will start with a small implementation, and then work my way up to the paper devsh suggested (https://github.com/Devsh-Graphics-Programming/Nabla/pull/340)
The current way I will do, I will uniformally distribute a point over all surfaces within a scene
To find this point, I will iterate over all triangles and sum their areas until I have an area larger than rand() * totalSurfaceArea (I could use binary search but too many bugs and points of failure when implemented atm)
Then, I will generate a random point within the triangle and use that as my sampling point

Now this comes to part I really wish I would be able to delay in it's implementaton because it would mean a lot of debugging and frustration
I will need to implement a seperate kernel just for visibility, since NEE doesn't use closest intersection, it uses any intersection (in between p and p_l)

To implement as bug free as possible, I will start off with hardcoding the cornell box light, and picking a point that way

Then, I will implement the shadow kernel (connect as it was called in the wavefront path tracing blog article)

The actual information specifcs:
We will need to spawn 2 rays, one that is NEE and the other one that samples indirect light
Since the NEE ray will have a seperate kernel, we do not need to have two light accumulation buffers

Scratch that, one kernel for now since this is getting complicated (and there is one light anyway)
That means we will need 2 accumulation buffers, and an indicator to tell us which one
For each ray we spawn, we need to give a flag that it is either NEE or indirect, so when we actually hit a light, we can access the radiance buffer without a data race
In the present stage, we collect these back and average our results 

Now that I know how NEE works, the accum part becomes useless, and I just need to store an integer flag

In the shade stage, we issue two new rays, one that is NEE and one that isn't (the sample type is 0)
NEE chooses a path on the light, and we do the pdf and whatnot, and then do russian roulette
Indirect chooses a cosine weighted path, do stuff and roulette again

However, with NEE we set sample type to 1, and indirect to 0
Then, the extend stage moves this value over back to the shade stage

If we hit a light, we know which image to write to based on this integer

UPDATE: did I actually implement NEE? no convergance gain
TODO: reorganize code, reorganize overything, rewrite, etc.
I need to restruct my pipeline so I can actually do NEE easily and all that jazz
I also need to read up on materials on how to actually do NEE with specular so I can structure my pipeline properly

Update: so what devsh taught me was that wavefront is bad, and for me it already is becomming a limitation
I think I will soon discard this supposedly faster algorithm for just plain old iterative tracing
The idea is to use coroutines between threads and thread groups
We make sure each thread group does one exact thing at a time
If they diverge, we simply exchange out divergent rays (or maybe all of them) to reobtain a set of rays that aren't divergent
This way we can have a whole lot more bounces

=================================================================
Haha, time flies, right? Since I'm visiting this project after a year, everything below the line goes in the garbage until I can clear my mind about what to do.

TODO LIST:
- Get to know my project again
- REWRITE AND REORGANIZE EVERYTHING!!!!!
- Fix bugs and whatnot

My vision for this project is getting a proper path tracer up and running only within OpenGL by next summer. 

For reorganizing, I can follow the GLSL-PathTracer repo. What they did was organizing the project like this
|-res
||-folder for object 1
|||-object file and textures
||-folder for object 2
|||-object file and textures
||-folder for object N
|||-object file and textures
|-extern
||-usual dependencies
|-src
||-Main.cpp
||-Rendering folder
||-Math folder
||-Misc folder

The main part is the src folder. A global Main.cpp file takes care of high level stuff, like window and GUI
It then proceeds to call a renderer object, which takes control of everything
So for example, the per frame render() function in main.cpp was simply just a call renderer->render() then a few high level opengl commands to present
This entire organization makes it very easy to understand the code, albiet a bit of commenting is needed (but also unncessary)

Naming convention wise, I am finally going to give up NamingEveryVariableLikeThis because it becomes hard to discern between functions, types, and variables
I will now move onto namingVariablesLikeThis. While mixed case looks ugly, it certainly is better than my NotWidelyUsedFormat and hellala lot better than mVarName or VarName_ like how google does it

DONE!!!!!: I will rename all the folders in extern to the normal project names instead of capitalizing everything (GLFW vs glfw)
I really one day need to learn how to properly include external projects instead of compiling by source through a submodule

I need to clean up the res folder instead of having many useless things laying around

Finally, an important bit. I'm giving up my weird obbsession with trying to support old hardware. 
I would often limit myself to OpenGL 3.3 and sometimes even thing of staying at 2.0 just for a little bit more hardware support
But now, it is 2022. Literally anything that doesn't belong in a dumpster runs all the new fancy APIs and OpenGL versions.
I think 4.5 is good enough for my features, but I will not hesitate jumping over to 4.6 if I need something or using a not-so-widely used (but still not vendor specifc) extension
What this means is that I am going to throw buffer textures out the window and begin using buffer objects
Overall, I will rewrite the opengl stuff to not be an API covering everything up and replacing it with my own layer, but as an actual application where certain duties are divided up accordingly
If you think about it, the only place you would want to completely cover up the API is when you want to add multiple API support to say, a game engine
Here I am staying down to earth and will implement with one API
No more unnessary abstraction. No more OCD.

I also really need to clean up my shaders folder. Once again, the GLSL path tracer project comes in hand. 
The shader folder is directly full of kernels, and a subfolder called "common" contains shared stuff like the RNG library

Here's my plan of attack:
- DONE: rename submodules because it is easiest
- Done: Clean res folder of useless junk (or organize it)
- Done: Move it outside of the src folder (might need to change debugging directory)
- Done?: *Reorganize sources folder, this includes a rewrite
- Doneish: Clean up of junk code and proper placement of comments
- Finish rewriting variable names
- Hopefullly I will be done by here!

*Now for the remaining tasks:
If we look to the GLSL path tracer, there are really just 3 folders:
1. The rendering stuff, where the meat of the code is
2. Math stuff, which contains basically the transform class and nothing more
3. Loading stuff, which I don't need since I don't require an over-the-top loader yet and assimp will suffice
If we look at my case, I have the odd stuff the GLSL path tracer doesn't have, such as a timer file, window, etc.
It would probably be better to have three folders: "core", "math", and "misc"

After my plan of attack, what I will do is:
- Fix my BVH traversal, reading the stackless paper "Efficient Stack-less BVH Traversal for Ray Tracing" gave me ideas, even though the authors stated the algorithm was slower than the stacked traversal

------------------------------------------------------------------------

This is the todo list

Things I need to do:
- DONE: Create a CPU side controlled camera with adjustable perspectivity 
- DONE: Allow that camera to move and look around
- DONE: Replace the ray-sphere intersection with a ray-triangle intersection
- DONE: Send the triangles to the shader using a SSBO or texture
- DONE: Dynamically load the triangles with ASSIMP
- DONE: Bounding volumes
- DONE: Bounding volume hierarchies 
- DONE: Texturing
- Better BVH building and traversal
- Wavefront ray tracing
- Scene loading
- Scene management system
- Monte carlo path tracing
- Post processing
- PARTIALLY DONE: Physically based rendering
- Importance sampling
- Multiple importance samping

Issues that I need to fix:
- FIXED: Ray triangle intersection and hidden surface removal is broken

Things I should do but don't need to:
- Fix OpenGL abstraction issues
- DONE: Add GLSL include directory functionality 
- Fix memory leaks and OpenGL resource "leaks" after the program exits

Things maybe I should do:
- Move to watertight triangle intersection